Q: 만약에 activation func을 사용하지 않고 그냥 layers을 진행 할 경우? 
단일의 linear 한 func으로 표현 가능해짐
y=ax 라는 linear 함수가 있다면, 1번째 층에선 y=ax이고, 2번째 층에선 y=a(ax), 3번째 층에선 y=a(a(ax)),.. 이런식 일 것임
그래서 은닉계층이 없는 단일 계층을 사용하는 것의 결과가 나타날 것임(즉, linear classification 이 됨)

# Parameter update
### stochastic Gradient 은 왜 느릴까?
![image](https://user-images.githubusercontent.com/56099627/70980180-39ae7680-20f6-11ea-8fd0-a7b11cf981d7.png)  
(그림) loss func 이 수직으로는 경사가 급함, 반면 수평으로는 경사가 완만함. 그래서 수렴하기까지 오랜 시간이 걸려. 이런 문제를 해결하기 위해서 momentum이 생김






참고  
[1] http://cs231n.stanford.edu/2016/syllabus.html, (설명) Andu song
[2] https://www.youtube.com/watch?v=5t1E3LZ3FDY, cs231n 6강 Training NN part 2
