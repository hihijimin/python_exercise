{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch03실습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hihijimin/python_exercise/blob/master/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D%3A%20ch03%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jloQomFy3yI-",
        "colab_type": "code",
        "outputId": "76d00ba6-bf97-4010-cc57-2535c5ac4690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muX_f_k24JFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks/deep-learning-from-scratch-master\")  # 부모 디렉터리의 파일을 가져올 수 있도록 설정"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuR497pL9FUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "dataset_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"MNIST 데이터셋 읽기\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
        "    one_hot_label : \n",
        "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
        "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
        "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])    \n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_mnist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyrOJYj99LNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "da3cec80-d2d0-409b-def3-30bb966988ad"
      },
      "source": [
        "# p99 mnist 데이터 셋\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def img_show(img):\n",
        "    pil_img = Image.fromarray(np.uint8(img))\n",
        "    pil_img.show()\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "print(label)  # 5\n",
        "\n",
        "print(img.shape)  # (784,)\n",
        "img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
        "print(img.shape)  # (28, 28)\n",
        "\n",
        "img_show(img)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "(784,)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfrzIcFE4LQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# p100 신경망의 추론 처리\n",
        "import numpy as np\n",
        "import pickle\n",
        "from dataset.mnist import load_mnist\n",
        "from common.functions import sigmoid, softmax\n",
        "\n",
        "def get_data():\n",
        "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "    return x_test, t_test\n",
        "\n",
        "def init_network():\n",
        "    with open(\"/content/gdrive/My Drive/Colab Notebooks/deep-learning-from-scratch-master/ch03/sample_weight.pkl\", 'rb') as f:\n",
        "        network = pickle.load(f) #학습된 가중치 매개변수: 가중치, 편향 매개변수가 딕션너리 변수로 되어 있음\n",
        "    return network\n",
        "\n",
        "def predict(network, x):\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, W3) + b3\n",
        "    y = softmax(a3)\n",
        "\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yplZkAQp4bj5",
        "colab_type": "code",
        "outputId": "04df5dc5-2c10-4594-81cc-3f6056548815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, t = get_data()\n",
        "network = init_network()\n",
        "accuracy_cnt = 0\n",
        "for i in range(len(x)):\n",
        "    y = predict(network, x[i])\n",
        "    p= np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
        "    if p == t[i]:\n",
        "        accuracy_cnt += 1\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}