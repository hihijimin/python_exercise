## torch to tensorRT
https://github.com/NVIDIA-AI-IOT/torch2trt/  

### 환경셋팅
HRnet-pose estimation 환경셋팅 한 conda env에 해줬다

    Option 1 - Without plugins (내장된 model 사용할 때)
    To install without compiling plugins, call the following

    git clone https://github.com/NVIDIA-AI-IOT/torch2trt
    cd torch2trt
    sudo python setup.py install

    Option 2 - With plugins (experimental)(pre_trained model에 적용할 때 )
    To install with plugins to support some operations in PyTorch that are not natviely supported with TensorRT, call the following

    Please note, this currently only includes the interpolate plugin. This plugin requires PyTorch 1.3+ for serialization.

    sudo apt-get install libprotobuf* protobuf-compiler ninja-build
    git clone https://github.com/NVIDIA-AI-IOT/torch2trt
    cd torch2trt
    sudo python setup.py install --plugins
  
### Error 발생
- **ModuleNotFoundError: No module named 'distutils.core'** 해결 위해 distutils 을 설치한다.  
https://github.com/kyuupichan/electrumx/issues/464  
$ sudo apt-get install python3-distutils  
![image](https://user-images.githubusercontent.com/56099627/84639400-49870600-af33-11ea-9e4f-7e00548ee30d.png)  
- **fatal error: Python.h: 그런 파일이나 디렉터리가 없습니다** 해결 위해 python-dev 을 설치한다.  
https://c10106.tistory.com/2600  
$ sudo apt-get install python3-dev  
![image](https://user-images.githubusercontent.com/56099627/84640256-653edc00-af34-11ea-8704-52afeb3585fc.png)  
- **fatal error: NvInfer.h: 그런 파일이나 디렉터리가 없습니다** 해결 위해 
-> tensorTR 설치해야 할듯 NvInfer.h 파일이 tensorRT에 있음...

### tensorRT 설치 
0. tensorRT에 대한 전반적인 내용 소개: https://developer.nvidia.com/tensorrt  
tensorRT 깃헙 소개 오픈소스 제공 https://github.com/NVIDIA/TensorRT  
참고! https://eehoeskrap.tistory.com/302  

1. tensorRT 파일 다운로드  
https://developer.nvidia.com/nvidia-tensorrt-7x-download  
![image](https://user-images.githubusercontent.com/56099627/84734958-3f214680-afdd-11ea-81f1-2c044a8be652.png)  

2. tensorRT 압툭 해제  
$ tar xzvf TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.0.cudnn7.6.tar.gz  

3. LD_LIBRARY_PATH 추가하기  
export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/media/jimin/D/D_ubuntu/TensorRT-7.0.0.11/lib  
(저장: $ source ~/.bashrc , 확인: $ echo $LD_LIBRARY_PATH)  

4. whl 파일 설치  
$ cd TensorRT-7.0.0.11/python  
$ pip3 install tensorrt-7.0.0.11-cp36-none-linux_x86_64.whl (for python 3.x)  

$ cd TensorRT-7.0.0.11/uff  
$ pip3 install uff-0.6.5-py2.py3-none-any.whl  

위치 /usr/local/bin/convert-to-uff 인지 확인 $ which convert-to-uff  

$ cd TensorRT-7.0.0.11/graphsurgeon  
$ pip3 install graphsurgeon-0.4.1-py2.py3-none-any.whl (for python 3.x )  

5. 확인  
$ python  
import tensorrt as trt  



