# Data Augmentation
![image](https://user-images.githubusercontent.com/56099627/71350115-ea63bc80-25b3-11ea-8195-a5c613500f97.png)  
- 고양이라는 레이블은 변함이 없고 픽셀의 내용을 변화 시킴, 변경된 픽셀 내용을 학습함
### 1. Horixontal flips
![image](https://user-images.githubusercontent.com/56099627/71350233-3878c000-25b4-11ea-8a6e-53f28d850e0e.png)  
- 미러 이미지라고 표현 하기도함 왼-오른쪽 반대방향으로 표현 되기 때문에  
### 2. Ramdom crops/ scales
<p align="center"><img width="50%" src="https://user-images.githubusercontent.com/56099627/71351500-2d735f00-25b7-11ea-83d8-28024569123c.png" /></p>  
- 이미지를 랜덤하게 잘라주고 랜덤한 크기를 가지는 이미지를 학습한다.
- 예를 들어 resnet에서는
  - 256, 480 범위에 있는 수를 선택해주고 학습 이미지를 resize을 해준다. 이미지의 사이즈가 짧은 곳이 L이 되도록 해준다.그리고 랜덤하게 224x224의 크기를 가지는 patch을 샘플링하여 추출한다.(224x224는 resnet에 들어가는 인풋 사이즈임)
- data augmentation를 이용하면 train 시에 이미지 전체가 아니라, 이미지 부분부분에 대한 학습이 이뤄지기 때문에 
  - test 시, 테스트할 이미지를 5개의 크기로 resize 해준다(224,256,384,480,640). 그런 후, 각각 사이즈에 대해 224x224 크기를 가지는 10개의 crop을 만들어준다( 코너 부분 crop 4개, 중심부분 crop 1개 -> 이를 filp 해줘서 10개를 생성한다). 5가지 사이즈므로 50개가 생긴다) 그리고 이 50개에 대해 평균을 구한다. 
### 3. Color jitter
![image](https://user-images.githubusercontent.com/56099627/71352309-5268d180-25b9-11ea-9c48-d286d075cfc1.png)  
- simple 방법: contrast을 jittering 시켜주는 방법(위 그림 예)
- 복잡한 방법: 이미지의 R, G, B 각각 채널에 PCA을 적용해줌. 각각 채널에 대해 principle componenet direction이 얻게될 것임. 컬러가 변화해 가는 방향성을 파악하게 함. principle componenet direction에 따른 컬러의 offset을 샘플링해줌(색을 보정시켜줌). offset을 이미지의 모든 픽셀에 더해준다.  
### Data Augmentation 요점 및 결론
![image](https://user-images.githubusercontent.com/56099627/71352869-c9529a00-25ba-11ea-9365-02a05d781ba4.png)
- training은 랜덤 노이즈를 더해주는 구조?
- testing은 더해준 노이즈를 평균화해주는 구조? (average out)
- 구현하기에 간단하므로 사용하는 편이 좋으며 데이터양이 적을땐 사용하라. 

# Trainsfer Leaning
![image](https://user-images.githubusercontent.com/56099627/71353533-afb25200-25bc-11ea-861c-1199f8f70341.png)  
- image net과 같이 데이터가 충분할 땐 1번과 같이 training, 학습 데이터가 매우 작을 땐 2번과 같이 아랫단(fc-1000, siftmax)에서 training, 학습할 데이터 양이 조금 있다면 finetuning으로 아랫단(conv-512, conv-512, maxpool, fc-4096, fc-4096, fc-1000, siftmax)에서 training 함
- Trainsfer Leaning 방법으로 학습하는 것이 처음부터 학습시키는 것보다 일반적으로 성능이 잘나온다. 이유는 이미지넷으로 학습시킨 pre-training 이미지(이미지넷 이미지)와 유사한 이미지로 classficaation을 해야하는 경우라면, 끝쪽만 학습시켜도 좋은 성과를 가진다. 이미지넷과 전혀 관련없는 이미지(의료 CT, MRI 데이터)을 아랫단만 아니라 상대적으로 상위 단까지 학습시켜야만 함. 관련없는 이미지로 학습 시키는데도 왜 성능이 좋아지냐면, 필터를 보면 앞단에선 로우레벨 feature의 이미지를 학습하고 뒷단으로 갈수록 추상적인 feature를 학습 하기 때문에 그 어떤 이미지를 학습하는데 도움이 된다.
- 학습 모델의 재사용
  
# convolutions
### how to stack them
![image](https://user-images.githubusercontent.com/56099627/71354998-face6400-25c0-11ea-9dfe-31c69ef9abe1.png)  
- 3x3 conv layer을 2번 stack 하는 것은 signle 5x5 convlution 하는 것과 같다
![image](https://user-images.githubusercontent.com/56099627/71354972-e7bb9400-25c0-11ea-93b6-8a32a5cf6c86.png)  
- 3x3 conv layer을 3번 stack 하는 것은 signle 7x7 convlution 하는 것과 같다
<p align="center"><img width="60%" src="https://user-images.githubusercontent.com/56099627/71355251-cb6c2700-25c1-11ea-8a52-81e7f738a2ac.png" /></p>  
- 7x7 filter을 한번에 사용하는 것보단 3x3 filter을 3번을 쓰는게 **파라마터가 더 적고(연산량 줄고)** 3개의 layer을 거치면서 **relu 등의 activation을 거치면서 nonlinearity 측면에서 더 좋아지게 된다**. (작은 필터의 강력함!)
![image](https://user-images.githubusercontent.com/56099627/71355552-c3f94d80-25c2-11ea-828c-c2ef54aae603.png)  
![image](https://user-images.githubusercontent.com/56099627/71355907-e17ae700-25c3-11ea-9c20-d9bc0309925c.png)  
- (그림) 그렇다면 3x3 filter 보다 더 작은 1x1 filter을 사용하면 되지 왜 사용하지 않느냐
  - 1x1 conv layer을 활용하는것을 'Network in network'이라 표현하고 'bottleneck convolution'이라 함
  - 이러한 방법은 유용성이 많이 입증 되었는데 googlenet 또는 Resnet 에서 쓰인다
- 1x1xcxc/2 + 3x3xc/2xc/2 + 1x1xc/2xc = 3.25 c_2 parameters
- 3x3xcxc = 9 c_2 parameters  
### how to compute them
![image](https://user-images.githubusercontent.com/56099627/71356718-649d3c80-25c6-11ea-9d6c-e2a8ec7ab8ee.png)   
**(implementing convolutions 예1) im2col**  
- matrix multiplication은 원래가 빠른 연산인데 대부분의 모든 플랫폼에서 아주 잘 최적화하여 구현해 놓은 상태 임  
- convolution을 martix multiplication으로 표현 해볼수 있지 않을까  
  
![image](https://user-images.githubusercontent.com/56099627/71357142-f8233d00-25c7-11ea-8e0b-05ca2ec2c6d4.png)  
  
![image](https://user-images.githubusercontent.com/56099627/71357087-bc887300-25c7-11ea-88f8-59165eceac69.png)  
**(implementing convolutions 예1) FFT**   
- 신호 f와 신호 g를 컨볼루션하는 것은 푸리에 트랜스폼의 요소간 곱을 하는 것과 동일하다 
- fast fourier trainsform 과 그 역행렬을 매우 빠르게 계산해내는 알고리즘임
![image](https://user-images.githubusercontent.com/56099627/71357021-759a7d80-25c7-11ea-9d0f-de46782c1d05.png)  
- 녹색이 스피트업 된 결과인데 필터가 큰 경우엔 적용효과가 좋지만 필터가 작은 경우 효과가 좋지 않다





  
참고  
[1] http://cs231n.stanford.edu/2016/syllabus.html, (설명) Andu song  
[2] https://www.youtube.com/watch?v=8kzgwfNSDfk, cs231n 11강 CNNs in practice
