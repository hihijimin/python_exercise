# Loss function 
score에 대해 불만족?하는 정도를 정량화하는 Loss func   
Loss func 최소화 하는 parameter을 찾는 과정 optimization  

## multiclass SVM loss : hinge loss
Loss func을 알아보기 위해 3개의 class을 가지는 예를 보자  
f(x,W) = Wx 을 이용해 score을 구함  
  
위 예를 가지고 2가지 loss을 알아볼거임  
- 1. SVM - Hinge loss  
- 2. softmax -cross entropy loss  
  
  
![image](https://user-images.githubusercontent.com/56099627/70791748-078dd380-1ddb-11ea-91ac-d07b1625ffa7.png)  
  
![image](https://user-images.githubusercontent.com/56099627/70791913-723f0f00-1ddb-11ea-92a7-7b7bb4958f53.png)  
  
**hinge loss (SVM loss)**  
- max(0, sj - sy +1) : 둘중 더 큰 값을 취하겠다  
- sj : 잘못된 레이블의 score   
- sy : 제대로된 레이블의 score  
- 1 : safety margin   
- 최종적으로 loss = (2.9 + 0 + 12.9) / 3 = 4.6  
  
Q1  
**j == y_i 이라면, 계산 하지 않고 있음**. 만약에 계산을 한다면, 
(safety margin 영향 으로) +1 만큼 해주기 때문에 +1 해준만큼 최종 loss 값이 높아질수 밖에 없다  
Q2  
각각의 loss 값을 구한 뒤 sum 해주고 나서 평균값 구하는데, 아예 각각 loss 구할때 평균 값 해준 뒤 각각을 더해주면 어떻겠느냐? 음... 결과적으로 비슷하지 않을까? 전체 합 하고 평균하거나 각 평균 후 합치거나~  
Q3  
max(0, sj - sy +1)^2 해준뒤 sum 하는건 어때(squared hinge loss)? 제곱하는거 자체가 linear 하지 않게 됨(non-linear)  
Q4  
SVM loss 에서 min/max 값에서 나올수 있는 범위(min/max)? max(0, sj - sy +1)의 좌/우 값 중에서 min은 0이 되겠고, max은 무한대가 되겠다  
Q5  
초기값 weight를 0에 가까운 수로 설정? 하는데 score는 0에 가까운 값이 나타날것인데 이 때의 loss 는 얼마가 되겠는가?  정답 2 (class가 3개 이므로, class가 10이라면 정답은 9 이겠죠)  
 ![image](https://user-images.githubusercontent.com/56099627/70802611-416bd380-1df5-11ea-92f8-ea936c20abae.png)  
   
   
![image](https://user-images.githubusercontent.com/56099627/70793369-7e789b80-1dde-11ea-8391-6c95cb0992fe.png)  
(그림설명) x: 인풋 vector, y: 레이블 integer 형태 값, W: weight matrix  
  
  
<p align="center"><img width="30%" src="https://user-images.githubusercontent.com/56099627/70803112-a2e07200-1df6-11ea-943d-91807bf507fa.png" /></p>   
score 값을 2배 한 것과 1배한 것과 동일 한 결과 값이 나온다. score 을 2배 한것이 중요한게 아니라 ' 0을 만드는 loss 값이 유니크 하지 않다는 점' 이다. 그래서 **unique한 loss 값을 생성하기 위해서 regularization 을 도입한다**  
  
  
![image](https://user-images.githubusercontent.com/56099627/70796501-c51dc400-1de5-11ea-95f3-d586a585277b.png)  
  
loss = (data loss)학습용 데이터를 최적화 하려 노력함 + (regularization)lambda : 일반화 하려고 노력함  
사실 regularization하는 과정을 넣으면 학습하는 과정 및 결과가 안 좋아지지만 **test Set 에 대한 퍼포먼스는 더 좋아진다.**  
regularization 입장에선 weight가 0이 되길 좋아하지 왜냐면 loss가 작아지므로  
하지만 다른편으로 생각하면 regularization 입장에선 절대 weight가 0이 될수 없어 왜냐면 분류를 해야하므로  
결론적으로 data loss 와 regularization 간의 싸움? 을 통해 더 훌륭한 결과를 낼수 있는 거  
  
![image](https://user-images.githubusercontent.com/56099627/70795267-c1d50900-1de2-11ea-9f6a-c99d2ec4825f.png)  
regularization 입장에선 w1 w2 둘중 어떤 걸 선호 할까?? **W2**  
이유 : w1은 1번 벡터에만 있어 1번 에만 영향력 있구, w2은 전체 벡터에 값이 존재해서 전체에 영향을 줄수 있어  
모든 인풋 피쳐들을 고려하길 원한다(diffuse over everything)  
즉 동일한 output이라면 spread out 되는 것을 선호합니다  
  
## softmax classifier : softmax loss
  
![image](https://user-images.githubusercontent.com/56099627/70803680-f99a7b80-1df7-11ea-9790-b6e5ed9a74a3.png)  
  
![image](https://user-images.githubusercontent.com/56099627/70796052-aa971b00-1de4-11ea-8cb8-4bcb384d1275.png)  
  
softmax classifier = multinomial logistic regression : 이항에 대한 로지스틱 리그레션을 다차원으로 일반화 한것이다.  
**score 정의 : 클래스를 log화 한 확률. nomalize 하지 않은 ~**  
**Loss = 정확한 class의 (-)마이너스 로그의 확률을 최소화 하자**  
**이것을 Cross Entropy Loss 라고 부름**  
  
Q4 soft max classifier 의 loss 에서 min/max 값에서 나올수 있는 범위(min/max)?  
x는 0~1 , y는 0(확률이 0, 형편없는 )에 가까울 때 무한대(loss 값)이고 1(확률이 1, 휼륭한)에 가까울 때는 0(loss 값)임  
<p align="center"><img width="30%" src="https://user-images.githubusercontent.com/56099627/70803843-58f88b80-1df8-11ea-9e67-2dcde17a0de3.png" /></p>   
  
Q5 초기값을 weight를 0에 가까운 수로 설정? 하는데 soft max classifier 의 loss 는 얼마가 되겠는가?  
![image](https://user-images.githubusercontent.com/56099627/70796849-8f2d0f80-1de6-11ea-9cc2-a4368d459118.png)  
  
## softmax 와 SVM 비교  
  
![image](https://user-images.githubusercontent.com/56099627/70804440-d83a8f00-1df9-11ea-866d-df630a3e2dd5.png)  
(그림설명) Wx+b 은 hinge loss와 cross-entropy loss와 동일함, 위 그림에선 ground true을 맨 아래 파란색 값으로 정의하고 설명하고 있는 거임(0.28  1.32  0.353)  
  
![image](https://user-images.githubusercontent.com/56099627/70804725-81818500-1dfa-11ea-8914-b704e322b0f8.png)  
Q 데이터 값이 있고 **score 값을 약간 조정한다면** loss에 어떤일이 발생 할까?  
svm은 safety margin 값이 있어 robustness 을 제공해주기 때문에 loss 값이 변화하지 않을 거임<불변>  
softmax는 모든인자들을 고려하는 특성이 있어 조정한 score 값에 매우 민감한편  
  
# Optimization  
loss를 minimize 하는 weight을 찾아가는 과정  
  
![image](https://user-images.githubusercontent.com/56099627/70798092-635f5900-1de9-11ea-923a-8ab031b3e55a.png)  
- dataset x,y 가 있음  
- score function은 Wx( x에 W을 곱해주는 것)  
- loss function은 softmax loss, SVM loss가 있으며, full loss =softmax loss/ SVM loss + regularization  
- regularization loss은 data의 loss가 아닌 weight의 로스 얌(weight에만 영향을 받는다는 점)  
   
**optimization 하는 전략으로 몇가지가 있는데**  
- strategy 1) Ramdom search : 인풋데이터들을 랜덤하게 추출해서 weight 값을 구하는거  
    - 참고: **(좋은 방법은 아님)**  
- strategy 2) Follow the slope : 미분하여 gradient 추출(벡터형태)  
    - 참고: 수치로 미분하는 것을 numerical gradient 라고 함  
    - numerical gradient 단점 : 근사치를 추출하는 것임, 평가시 속도가 매우 느림 (장점) 코드로 작성하기 쉽다.  
    - analytic gradient 담점 : 코드로 작성하기 어렵다 (장점) 정확하고 빠르다  
    - 결론 : analytic gradient을 사용하되 시작 시점에서 numerical gradient을 사용하여 check 를 해보자  
    
**Gradient Descent**  
while true:  
weight_grad = evaluate_gradient(loss_func, data, weights)  
weights += -step_size x weight_grad # parameter update  
  
**full Gradient Descent**  
training 배치 셋 전체를 사용하는 것인데 속도가 너무 느려  
  
**mini-batch Gradient Descent**  
training 셋 의 일부만 사용하여 gradient 계산-> parameter 업데이트 해줌 -> 다음 배치를 학습 -> gradient 계산 ...
일반적으로 batch size은 32/64/128/256 으로 가짐  
어떻게 미니 배치 사이즈를 정하는냐는 하이퍼파라메터는 아니지만 나의 PC 환경(CPU, GPU)에 맞게 설정해주면 된다  
  
![image](https://user-images.githubusercontent.com/56099627/70843553-b67fed00-1e77-11ea-973c-d0bed09aafc5.png)  
  
미니배치 를 사용하면 (단기적)노이즈처럼 파형이 그려지는데 (장기적)점차 loss가 줄어듬  
128개의 데이터를 사용해 파라미터를 업데이트 하고 다시128개 데이터 사용해 파라미터 업데이트 때문에 일시적으로 loss가 증가했다가 줄어들었다하는 양상을 보인다 장기적으로 보면 loss가 줄어들지  
learning rate - loss 간 좋은 learning rate는 뭘까? 쉽지 않아  
매우 크게 하면 diverge/ explode  
다소 높게 하면 loss가 최저점으로 가지 못하는 현상 생김  
넘 작을 하면 loss가 최저점까지 달성하는데 굉장히 오랜 시간이 걸린다  
  
' 미니배치 GD의 예는 Stochastic Gradient Descent 있음 '  
파라미터를 업데이트 하는 방식은 GD 뿐만 아니라, momentum, adagrad, RMSProp, Adam,.. 존재  
momemtum은 로스가 줄어드는 속도까지 조절함 - 그래서 그 속도를 트랙킹하면서 진행하기 때문에 loss에 도달하는데 더빠른 효과 있음  
  
# 전통적인 image classify  
fearture 추출 후 추출한 feature 들을 하나로 합친다 그런 후, linear classification에 적용한다  
  
   
## feature을 추출하는 방법  
![image](https://user-images.githubusercontent.com/56099627/70843649-14f99b00-1e79-11ea-9903-40da378745f1.png)  
(그림설명) 1번 방법) color(hue) histogram  
이미지내에 있는 모든 컬러를 파악한다. 그런 후, 컬러 파노라마가 있을때 각각에 해당하는 'bin'이 몇개인지 카운트 한다.  
  
![image](https://user-images.githubusercontent.com/56099627/70843685-cac4e980-1e79-11ea-9456-ca7e1f6d944c.png)   
(그림설명) 2번 방법) HOG /SIFT features  
엣지의 방향이 feature가 된다. 8x8 픽셀로 구성된 구역을 보면서 그 엣지들의 방향을 총 9가지로 구분을 해서(9개 bin) 9개 bin에 어디에 속하는지를 기준으로 해서 엣지의 오리엔테이션을 추출하는 거  
  
 ![image](https://user-images.githubusercontent.com/56099627/70843697-3eff8d00-1e7a-11ea-8395-2429f287d244.png)  
(그림설명) 3번 방법) Bag of Words  
이미지의 여러지점들을 보고 그 작은지점(작은 로컬 패치들)을 frequency or color 등을 'vector'로 기술한다. 이것들을 모아 하나의 어떤 '사전화'를 한다. 이 사전 중에서 테스트할 이미지와 가장 유사하게 생긴 어떤 feature vector을 사전내에서 찾는다. 찾을 때는 k-means 방법을 이용한다. 이 feature vectors을 추출하고 concatenation을 한다음 linear classification을 적용해 준다.  
  
![image](https://user-images.githubusercontent.com/56099627/70843871-3f992300-1e7c-11ea-9a68-412ab3e852dc.png)  
- 정통적 방법 : feature 추출한 후, 이것들을 concatenation 해준 뒤, linear classification 함수의 인자로서 던져줌으로서 결과를 얻음  
- 현재 방법(딥러닝) : feature 추출을 인위적으로 하지 않고 이미지 자체를 classifier에 인자로 던져주면 모델(함수)가 알아서 결과를 출력해준다  

  
  
참고  
[1] https://www.youtube.com/watch?v=KT4iD6yiqwo&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=2, cs231n 3강 Loss fn, optimization  
[2]   
