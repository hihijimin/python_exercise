# python-openpose 적용
- video 실행
예시: (ahn) D:\openpose-master> build\x64\Release\OpenPoseDemo.exe --video examples/media/kdn1.mp4  
- Python API about Videos
아래 참고사이트에서 openpose-video/realtime camera 으로 skeleton 사용 가능한 코드 적혀 있음  
https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/1091  
https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html  
- 참고 1  
https://medium.com/pixel-wise/real-time-pose-estimation-in-webcam-using-openpose-python-2-3-opencv-91af0372c31c  
  - 여긴 어떤 외국인이 작성한 블로그, 웹캠으로 keypoint 추출함
  - 추가 참고 코드:  
  https://github.com/nishagandhi/OpenPose_PythonOpenCV
- 참고 2 (내용 그대로 복사해옴)  
https://blog.naver.com/PostView.nhn?blogId=rhrkdfus&logNo=221531159811&parentCategoryNo=&categoryNo=29&viewDate=&isShowPopularPosts=true&from=search  
https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/  
  -  OpenPose 다운받기  
    
        (1) 아래의 GitHub에 들어가 OpenPose 파일들을 다운받습니다.  
          * [Clone or download] - [Download ZIP]  
          [openpose] https://github.com/CMU-Perceptual-Computing-Lab/openpose  
        (2) 압축 해제 후 [models] - "getModels" 파일 실행  
          * windows 환경에서 실행하는 것이고, 그 외 Linux환경에서는 getModels.sh를 실행시킵니다.  
          * 파일이 제대로 실행되면 각 모델을 다운로드 해줍니다.  
        (3) 코드를 실행할 때는 아래 두개 파일만 필요합니다. 적절한 위치에 복사해주세요(python)  
          - pose_deploy_linevec_faster_4_stages.prototxt  
          - pose_iter_160000.caffemodel  
      
  - 모델 가져와 keypoint 검출하기(keypoint-keypoint끼리 연결하는건 오류가 많은편..)
  
        # fashion_pose.py : MPII를 사용한 신체부위 검출
        import cv2

        # MPII에서 각 파트 번호, 선으로 연결될 POSE_PAIRS
        BODY_PARTS = { "Head": 0, "Neck": 1, "RShoulder": 2, "RElbow": 3, "RWrist": 4,
                        "LShoulder": 5, "LElbow": 6, "LWrist": 7, "RHip": 8, "RKnee": 9,
                        "RAnkle": 10, "LHip": 11, "LKnee": 12, "LAnkle": 13, "Chest": 14,
                        "Background": 15 }

        POSE_PAIRS = [ ["Head", "Neck"], ["Neck", "RShoulder"], ["RShoulder", "RElbow"],
                        ["RElbow", "RWrist"], ["Neck", "LShoulder"], ["LShoulder", "LElbow"],
                        ["LElbow", "LWrist"], ["Neck", "Chest"], ["Chest", "RHip"], ["RHip", "RKnee"],
                        ["RKnee", "RAnkle"], ["Chest", "LHip"], ["LHip", "LKnee"], ["LKnee", "LAnkle"] ]

        # 각 파일 path
        protoFile = "D:\\python_D\\fashion_data\\pose_deploy_linevec_faster_4_stages.prototxt"
        weightsFile = "D:\\python_D\\fashion_data\\pose_iter_160000.caffemodel"

        # 위의 path에 있는 network 불러오기
        net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)

        # 이미지 읽어오기
        image = cv2.imread("D:\\python_D\\fashion_data\\full_body7.png")

        # frame.shape = 불러온 이미지에서 height, width, color 받아옴
        imageHeight, imageWidth, _ = image.shape

        # network에 넣기위해 전처리
        inpBlob = cv2.dnn.blobFromImage(image, 1.0 / 255, (imageWidth, imageHeight), (0, 0, 0), swapRB=False, crop=False)

        # network에 넣어주기
        net.setInput(inpBlob)

        # 결과 받아오기
        output = net.forward()

        # output.shape[0] = 이미지 ID, [1] = 출력 맵의 높이, [2] = 너비
        H = output.shape[2]
        W = output.shape[3]
        print("이미지 ID : ", len(output[0]), ", H : ", output.shape[2], ", W : ",output.shape[3]) # 이미지 ID

        # 키포인트 검출시 이미지에 그려줌
        points = []
        for i in range(0,15):
            # 해당 신체부위 신뢰도 얻음.
            probMap = output[0, i, :, :]
            # global 최대값 찾기
            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)
            # 원래 이미지에 맞게 점 위치 변경
            x = (imageWidth * point[0]) / W
            y = (imageHeight * point[1]) / H
            # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    
            if prob > 0.1 :    
                cv2.circle(image, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)       # circle(그릴곳, 원의 중심, 반지름, 색)
                cv2.putText(image, "{}".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)
                points.append((int(x), int(y)))
            else :
                points.append(None)

        cv2.imshow("Output-Keypoints",image)
        cv2.waitKey(0)

        # 이미지 복사
        imageCopy = image

        # 각 POSE_PAIRS별로 선 그어줌 (머리 - 목, 목 - 왼쪽어깨, ...)
        for pair in POSE_PAIRS:
            partA = pair[0]             # Head
            partA = BODY_PARTS[partA]   # 0
            partB = pair[1]             # Neck
            partB = BODY_PARTS[partB]   # 1

            #print(partA," 와 ", partB, " 연결\n")
            if points[partA] and points[partB]:
                cv2.line(imageCopy, points[partA], points[partB], (0, 255, 0), 2)


        cv2.imshow("Output-Keypoints",imageCopy)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
# 설치
## windows 10 환경에서 설치하고 python 에서 실행하기
- 참고1 을 보면서 설치 하였음  
https://hiseon.me/data-analytics/introduction-openpose/  
### 설치하면서 발생했던 문제: **python에서 import pyopenpose을 할수 없음**  
- 아래 참고한 사이트 보면서 해결 했음. 특히 pyopenpose.cp36-win_amd64.pyd 또는 pyopenpose.pyd 파일이 있어야 한다고 보구 vs2015(release)에서 빌드 시켰더니 pyopenpose.cp36-win_amd64.pyd 파일이 생성 되었음 해당 경로에 이 파일이 뙇 넣고나면 파이썬에서 실행 가능했음  

    Problem 2: Python for Openpose needs to be compiled in Release mode for now. This can be done in [Visual Studio](https://cdn.stereolabs.com/docs/getting-started/images/release_mode.png). Once that is done check this line:

    `sys.path.append(dir_path + '/../../python/openpose/Release');`

    ```
    dir ../../python/openpose/Release
    ```

    Check the contents of this location. It should contain one of the following files:

    ```
    pyopenpose.cp36-win_amd64.pyd
    pyopenpose.pyd
    ```

    If such a folder does not exist, you need to compile in Release mode as seen above. If you have the first one, you have compiled PyOpenPose for Python 3, and have to run the scripts with `python3`, and vice versa for the 2nd one. Follow the testing examples above for exact commands. If that still does not work, check this line:

    `os.environ['PATH']  = os.environ['PATH'] + ';' + dir_path + '/../../x64/Release;' +  dir_path + '/../../bin;'`

    ```
    dir ../../x64/Release
    dir ../../bin
    ```

    Ensure that both of these paths exist, as PyOpenPose needs to reference those libraries. If they don't exist, change the path so that they point to the correct location in your build folder.
참고 https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/modules/python_module.md  
- 그리고 아래 글도 참고 함
    
    Hello, I followed the tutorial and same problem ... but got a:

      Error: OpenPose library could not be found. Did you enable `BUILD_PYTHON` in CMake and have this Python script in the righ
      DLL load failed while importing pyopenpose: The specified module could not be found.
    Config:

    Windows Server 2019 - Python 3 - CUDA 10 - Visual Studio 2019

    This is my 01_body_from_image.py file:

      if platform == "win32":
        # Change these variables to point to the correct folder (Release/x64 etc.)
        sys.path.append(dir_path + '/../../python/openpose/Release');
        os.environ['PATH']  = os.environ['PATH'] + ';' + dir_path + '/../../x64/Release;' +  dir_path + '/../../bin;'
        import pyopenpose as op
    Files from command :

    dir ../../python/openpose/Release/

      pyopenpose.cp38-win_amd64.pyd pyopenpose.exp pyopenpose.lib

    dir ../../x64/Release/

      01_body_from_image_default.exe          11_asynchronous_custom_output.exe
      02_whole_body_from_image_default.exe    12_asynchronous_custom_input_output_and_datum.exe
      03_keypoints_from_image.exe             13_synchronous_custom_input.exe
      04_keypoints_from_images.exe            14_synchronous_custom_preprocessing.exe
      05_keypoints_from_images_multi_gpu.exe  15_synchronous_custom_postprocessing.exe
      06_face_from_image.exe                  16_synchronous_custom_output.exe
      07_hand_from_image.exe                  17_synchronous_custom_all_and_datum.exe
      08_heatmaps_from_image.exe              2_thread_user_input_processing_output_and_datum.exe
      09_keypoints_from_heatmaps.exe          ALL_BUILD
      1_custom_post_processing.exe            Calibration.exe
      1_thread_user_processing_function.exe   openpose.dll
      10_asynchronous_custom_input.exe        OpenPoseDemo.exe
    dir ../../bin/

      boost_filesystem-vc141-mt-x64-1_69.dll  cublas64_100.dll  glog.dll            opencv_videoio_ffmpeg411_64.dll
      boost_thread-vc141-mt-x64-1_69.dll      cudart64_100.dll  glogd.dll           opencv_world411.dll
      caffe.dll                               cudnn64_7.dll     libgcc_s_seh-1.dll  opencv_world411d.dll
      caffehdf5.dll                           curand64_100.dll  libgfortran-3.dll   VCRUNTIME140.dll
      caffehdf5_hl.dll                        gflags.dll        libopenblas.dll
      caffezlib1.dll                          gflagsd.dll       libquadmath-0.dll
  
참고: https://octolinker-demo.now.sh/CMU-Perceptual-Computing-Lab/openpose/issues/1427#issuecomment-559521056    

참고-Open Pose 개선 일지(진행과정/에러수정)  
https://m.blog.naver.com/PostView.nhn?blogId=worb1605&logNo=221322084609&proxyReferer=https%3A%2F%2Fwww.google.com%2F
