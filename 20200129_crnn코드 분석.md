참고  
[1] https://github.com/qjadud1994/CRNN-Keras 자동차번호판 번호인식 CRNN  
[2] https://github.com/qjadud1994/Korean-license-plate-Generator, 자동차번호판(이미지) 생성 코드  

    # Mpdel.py 코드 분석
    def get_Model(training):
    input_shape = (img_w, img_h, 1)     # (128, 64, 1)

    # Make Networkw
    inputs = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 128, 64, 1)

    # Convolution layer (VGG)
    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 128, 64, 64)
    inner = BatchNormalization()(inner)
    inner = Activation('relu')(inner)
    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)

    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 32, 128)
    inner = BatchNormalization()(inner)
    inner = Activation('relu')(inner)
    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)

    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)
    inner = BatchNormalization()(inner)
    inner = Activation('relu')(inner)
    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)
    inner = BatchNormalization()(inner)
    inner = Activation('relu')(inner)
    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  # (None, 32, 8, 256)

    inner = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 512)
    inner = BatchNormalization()(inner)
    inner = Activation('relu')(inner)
    inner = Conv2D(512, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)
    inner = BatchNormalization()(inner)
    inner = Activation('relu')(inner)
    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)

    inner = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 512)
    inner = BatchNormalization()(inner)
    inner = Activation('relu')(inner)

    # CNN to RNN
    inner = Reshape(target_shape=((32, 2048)), name='reshape')(inner)  # (None, 32, 2048)
    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)

    # RNN layer
    lstm_1 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)
    lstm_1b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)
    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)

    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)
    lstm1_merged = BatchNormalization()(lstm1_merged)

    lstm_2 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)
    lstm_2b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)
    reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)

    lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)
    lstm2_merged = BatchNormalization()(lstm2_merged)

    # transforms RNN output to character activations:
    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)
    y_pred = Activation('softmax', name='softmax')(inner)

    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32') # (None ,8)
    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)
    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)

    # Keras doesn't currently support loss funcs with extra parameters
    # so CTC loss is implemented in a lambda layer
    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)

    if training:
        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)
    else:
        return Model(inputs=[inputs], outputs=y_pred)
        
#######################################################  
00) training/adadelta/gradients/conv1/convolution_grad/Conv2BackpropFilter:0, shape=(3,3,1,64), flaot32  
01) training/adadelta/gradients/conv1/BiasAdd_grad/BiasAddGrad:0, shape=(64,) float32
02) training/adadelta/gradients/batch_nomalization_1/batchnorm/mul_grad/Mul_1:0 shape=64, flaot32
03) training/adadelta/gradients/batch_nomalization_1/batchnorm/sub_grad/Reshape:0 shape=64, flaot32
04) training/adadelta/gradients/conv2/convolution_grad/Conv2DBackpropFilter:0, shape=(3,3,64,128), flaot32
05) training/adadelta/gradients/conv2/BiasAdd_grad/BiasAddGrad:0, shape=(128), flaot32
06) training/adadelta/gradients/batch_nomalization_2/batchnorm/mul_grad/Mul_1:0 shape=(128,), flaot32
07) training/adadelta/gradients/batch_nomalization_2/batchnorm/sub_grad/Reshape:0 shape=(128,), flaot32
08) training/adadelta/gradients/conv3/convolution_grad/Conv2DBackpropFilter:0, shape=(3,3,128,256), flaot32
09) training/adadelta/gradients/conv3/BiasAdd_grad/BiasAddGrad:0, shape=(256,), flaot32
10) training/adadelta/gradients/batch_nomalization_3/batchnorm/mul_grad/Mul_1:0 shape=(256,), flaot32
11) training/adadelta/gradients/batch_nomalization_3/batchnorm/sub_grad/Reshape:0 shape=(256,), flaot32
12) training/adadelta/gradients/conv4/convolution_grad/Conv2DBackpropFilter:0, shape=(3,3,256,256), flaot32
13) training/adadelta/gradients/conv4/BiasAdd_grad/BiasAddGrad:0, shape=(256,), flaot32
14) training/adadelta/gradients/batch_nomalization_4/batchnorm/mul_grad/Mul_1:0 shape=(256,), flaot32
15) training/adadelta/gradients/batch_nomalization_4/batchnorm/sub_grad/Reshape:0 shape=(256,), flaot32
16) training/adadelta/gradients/conv5/convolution_grad/Conv2DBackpropFilter:0, shape=(3,3,256,512), flaot32
17) training/adadelta/gradients/conv5/BiasAdd_grad/BiasAddGrad:0, shape=(512,), flaot32
18) training/adadelta/gradients/batch_nomalization_5/batchnorm/mul_grad/Mul_1:0 shape=(512,), flaot32
19) training/adadelta/gradients/batch_nomalization_5/batchnorm/sub_grad/Reshape:0 shape=(512,), flaot32
20) training/adadelta/gradients/conv6/convolution_grad/Conv2DBackpropFilter:0, shape=(3,3,512,512), flaot32
21) training/adadelta/gradients/conv6/BiasAdd_grad/BiasAddGrad:0, shape=(512,), flaot32
22) training/adadelta/gradients/batch_nomalization_6/batchnorm/mul_grad/Mul_1:0 shape=(512,), flaot32
23) training/adadelta/gradients/batch_nomalization_6/batchnorm/sub_grad/Reshape:0 shape=(512,), flaot32
24) training/adadelta/gradients/conv7/convolution_grad/Conv2DBackpropFilter:0, shape=(2,2,512,512), flaot32
25) training/adadelta/gradients/conv7/BiasAdd_grad/BiasAddGrad:0, shape=(512,), flaot32
26) training/adadelta/gradients/batch_nomalization_7/batchnorm/mul_grad/Mul_1:0 shape=(512,), flaot32
27) training/adadelta/gradients/batch_nomalization_7/batchnorm/sub_grad/Reshape:0 shape=(512,), flaot32
28) training/adadelta/gradients/dense1/transpose_grad/transpose:0, shape=(2048,64), float32
29) training/adadelta/gradients/dense1/Reshape_3_grad/Reshape:0, shape=(64,), float32
30) training/adadelta/gradients/AddN_36:0, shape=(64,1024), float32
31) training/adadelta/gradients/AddN_35:0, shape=(256,1024), flaot32
32) training/adadelta/gradients/AddN_34:0, shape=(1024,), flaot32
33) training/adadelta/gradients/AddN_33:0, shape=(64,1024), flaot32
34) training/adadelta/gradients/AddN_31:0, shape=(256,1024), float32
35) training/adadelta/gradients/AddN_30:0, shape=(1024,), float32
36) training/adadelta/gradients/batch_nomalization_8/batchnorm_1/mul_grad/Mul_1:0 shape=(256,), flaot32
37) training/adadelta/gradients/batch_nomalization_8/batchnorm_1/sub_grad/Reshape:0 shape=(256,), flaot32
38) training/adadelta/gradients/AddN_18:0, shape=(256,1024,), float32
39) training/adadelta/gradients/AddN_17:0, shape=(256,1024,), float32
40) training/adadelta/gradients/AddN_16:0, shape=(1024,), float32
41) training/adadelta/gradients/AddN_15:0, shape=(256,1024,), float32
42) training/adadelta/gradients/AddN_13:0, shape=(256,1024,), float32
43) training/adadelta/gradients/AddN_12:0, shape=(1024,), float32
44) training/adadelta/gradients/batch_nomalization_9/batchnorm_1/mul_grad/Mul_1:0 shape=(512,), flaot32
45) training/adadelta/gradients/batch_nomalization_9/batchnorm_1/sub_grad/Reshape:0 shape=(512,), flaot32
46) training/adadelta/gradients/dense2/transpose_grad/transpose:0, shape=(512,42), float32  
47) training/adadelta/gradients/dense2/Reshape_3_grad/Reshape:0, shape=(42,), float32  
###########################################################
참고  
[1] CRNN 숫자인식  
  
    def BidirectionnalRNN(inputs, seq_len):
    """
        Bidirectionnal LSTM Recurrent Neural Network part
    """
    with tf.variable_scope(None, default_name="bidirectional-rnn-1"):
    # Forward
    lstm_fw_cell_1 = rnn.BasicLSTMCell(256)
    # Backward
    lstm_bw_cell_1 = rnn.BasicLSTMCell(256)

    inter_output, _ = tf.nn.bidirectional_dynamic_rnn(
        lstm_fw_cell_1, lstm_bw_cell_1, inputs, seq_len, dtype=tf.float32
    )

    inter_output = tf.concat(inter_output, 2)

    with tf.variable_scope(None, default_name="bidirectional-rnn-2"):
    # Forward
    lstm_fw_cell_2 = rnn.BasicLSTMCell(256)
    # Backward
    lstm_bw_cell_2 = rnn.BasicLSTMCell(256)

    outputs, _ = tf.nn.bidirectional_dynamic_rnn(
        lstm_fw_cell_2,
        lstm_bw_cell_2,
        inter_output,
        seq_len,
        dtype=tf.float32,
    )
    outputs = tf.concat(outputs, 2)

    return outputs
-----------------------
    def CNN(inputs):
        """
            Convolutionnal Neural Network part
        """

    # 64 / 3 x 3 / 1 / 1
    conv1 = tf.layers.conv2d(
        inputs=inputs,
        filters=64,
        kernel_size=(3, 3),
        padding="same",
        activation=tf.nn.relu,
    )

    # 2 x 2 / 1
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

    # 128 / 3 x 3 / 1 / 1
    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=128,
        kernel_size=(3, 3),
        padding="same",
        activation=tf.nn.relu,
    )

    # 2 x 2 / 1
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

    # 256 / 3 x 3 / 1 / 1
    conv3 = tf.layers.conv2d(
        inputs=pool2,
        filters=256,
        kernel_size=(3, 3),
        padding="same",
        activation=tf.nn.relu,
    )

    # Batch normalization layer
    bnorm1 = tf.layers.batch_normalization(conv3)

    # 256 / 3 x 3 / 1 / 1
    conv4 = tf.layers.conv2d(
        inputs=bnorm1,
        filters=256,
        kernel_size=(3, 3),
        padding="same",
        activation=tf.nn.relu,
    )

    # 1 x 2 / 1
    pool3 = tf.layers.max_pooling2d(
        inputs=conv4, pool_size=[2, 2], strides=[1, 2], padding="same"
    )

    # 512 / 3 x 3 / 1 / 1
    conv5 = tf.layers.conv2d(
        inputs=pool3,
        filters=512,
        kernel_size=(3, 3),
        padding="same",
        activation=tf.nn.relu,
    )

    # Batch normalization layer
    bnorm2 = tf.layers.batch_normalization(conv5)

    # 512 / 3 x 3 / 1 / 1
    conv6 = tf.layers.conv2d(
        inputs=bnorm2,
        filters=512,
        kernel_size=(3, 3),
        padding="same",
        activation=tf.nn.relu,
    )

    # 1 x 2 / 2
    pool4 = tf.layers.max_pooling2d(
        inputs=conv6, pool_size=[2, 2], strides=[1, 2], padding="same"
    )

    # 512 / 2 x 2 / 1 / 0
    conv7 = tf.layers.conv2d(
        inputs=pool4,
        filters=512,
        kernel_size=(2, 2),
        padding="valid",
        activation=tf.nn.relu,
    )
    return conv7
    batch_size = None
        inputs = tf.placeholder(
            tf.float32, [batch_size, max_width, 32, 1], name="input"
        )

        # Our target output
        targets = tf.sparse_placeholder(tf.int32, name="targets")

        # The length of the sequence
        seq_len = tf.placeholder(tf.int32, [None], name="seq_len")

        cnn_output = CNN(inputs)
        reshaped_cnn_output = tf.squeeze(cnn_output, [2])
        max_char_count = cnn_output.get_shape().as_list()[1]

        crnn_model = BidirectionnalRNN(reshaped_cnn_output, seq_len)

        logits = tf.reshape(crnn_model, [-1, 512])
        W = tf.Variable(
            tf.truncated_normal([512, self.NUM_CLASSES], stddev=0.1), name="W"
        )
        b = tf.Variable(tf.constant(0.0, shape=[self.NUM_CLASSES]), name="b")

        logits = tf.matmul(logits, W) + b
        logits = tf.reshape(
            logits, [tf.shape(cnn_output)[0], max_char_count, self.NUM_CLASSES]
        )

        # Final layer, the output of the BLSTM
        logits = tf.transpose(logits, (1, 0, 2))

        # Loss and cost calculation
        loss = tf.nn.ctc_loss(
            targets, logits, seq_len, ignore_longer_outputs_than_inputs=True
        )

        cost = tf.reduce_mean(loss)

        # Training step
        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)

        # The decoded answer
        decoded, log_prob = tf.nn.ctc_beam_search_decoder(
            logits, seq_len, merge_repeated=False
        )
        dense_decoded = tf.sparse_tensor_to_dense(
            decoded[0], default_value=-1, name="dense_decoded"
        )

        # The error rate
        acc = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), targets))

        init = tf.global_variables_initializer()
===========================================================  
conv1: conv2d/relu:0, shape=(none,100,32,64), float32  
pool1: mas_pooling2d/MaxPool:0, shape=(none,50,16,64), float32  
conv2: conv2d_1/relu:0, shape=(none,50,16,128), float32  
pool2: mas_pooling2d_1/MaxPool:0, shape=(none,25,8,128), float32  
conv3: conv2d_2/relu:0, shape=(none,25,8,256), float32  
bnom1: batch_normalization/FusedBatchNorm:0, shape=(none, 25,8,256), float32  
conv4: conv2d_3/relu:0, shape=(none,25,8,256), float32  
pool3: mas_pooling2d_2/MaxPool:0, shape=(none,25,4,256), float32  
conv5: conv2d_4/relu:0, shape=(none,25,4,512), float32  
bnom2: batch_normalization_1/FusedBatchNorm:0, shape=(none, 25,4,512), float32  
conv6: conv2d_5/relu:0, shape=(none,25,4,512), float32  
pool4: mas_pooling2d_3/MaxPool:0, shape=(none,25,2,512), float32  
conv7: conv2d_6/relu:0, shape=(none,25,1,512), float32  
cnn_output: (24,1,512) -> (24,512)  
  
lstm1_out_1: bidirectional-rnn-1/bidirectional_rnn/fw/fw/transpose_1:0, shape=(none,24,256), float32  
lstm1_out_2: bidirectional-rnn-1/ReverseSequence:0, shape=(none,24,256), float32  
-> lstm1_out: shape=(none,24,256), float32  
lstm2_out_1: bidirectional-rnn-2/bidirectional_rnn/fw/fw/transpose_1:0, shape=(none,24,256), float32  
lstm2_out_2: bidirectional-rnn-2/ReverseSequence:0, shape=(none,24,256), float32  
-> lstm2_out: shape=(none,24,512), float32  
  
