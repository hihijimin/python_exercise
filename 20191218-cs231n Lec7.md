# Convolution Neural Network


- 32x32 image 위에 5x5 filter을 convolution 해주면 28x28x1 activation map 이 생성
- re-represetation
![image](https://user-images.githubusercontent.com/56099627/71056490-c7dd3800-219c-11ea-96aa-20dd5bb87ecf.png)  
(그림) 바로 앞단에 기반하여 visualization 한 것임 : 1st filter은 이미지를 visualization 하게 된 것이고 2nd filter을 visualization 한것임 ...
  
![image](https://user-images.githubusercontent.com/56099627/71056960-6cac4500-219e-11ea-9bd7-edc506a03346.png)  
(그림) 32개의 5x5 filters 가 있는데 각각이 주는 filter map 이 됨 (activation 에서 하얀색 부분이 activation이 높은지점) filter와 image 간의 convolution 한 것임.
  
![image](https://user-images.githubusercontent.com/56099627/71057133-0247d480-219f-11ea-9cf3-eda060aab8d2.png)  
(conv-relu-conv-relu-pooling) - ... - Fullyconnected convolution(이 단계에서 classification 됨)  
  - conv layer에선 계속해서 사이즈를 유지해지므로 pooling layer가 필요함
10개의 filter에서 10개의 activation map을 생성함. 이 10개의 activation map 전체를 volume 이라고 말함  

- 필터를 이미지위에 필터 시킨다 1 filter 1 actiavation map
- ( image의 width또는 hight - filter의 width또는 hight / stride ) +1 = (32-5/1) +1

- padding을 쓰면 이미지 사이즈를 보존할 수 있다
  - 왜 중요할까? padding을 안하면 voulme 자체가 계속 줄어들게 된다 즉, convenience, re-presentation 차원에서 유용하다. padding을 이용해서 size을 보존해 줌. 때론 size을 줄이는 것(downsampling)이 의미가 있을 때도 있음(-> 이건 pooling layer에서 관련 있음)

![image](https://user-images.githubusercontent.com/56099627/71063483-1a741f80-21b0-11ea-82e5-ca6d14affaa1.png)
(그림) 생성되는 파라미터 개수는?
일반적으로 filter의 개수를 일반적으로 2의 n승 으로 해줌. 왜냐하면 convenience, perfomance 측면에서 유리 하므로

동일한 depth 내에 뉴런들은 동일한 weight(parameters) sharing을 함
동일한 activation map 위치에 있는 뉴런들은 동일한 local connectivity을 쳐다본다

# Pooling layer
volume 을 작게 representation 하고 좀 더 manageable 할 수 있게 해줌, 각각의 activation map을 독립적으로 작용할 수 있도록 해줌
<p align="center"><img width="40%" src="https://user-images.githubusercontent.com/56099627/71064887-77bda000-21b3-11ea-9bed-0d59ab141041.png" /></p> 
(그림) volume 은 224x224x1 이고 224x224x64 가 activation map 임

# Fully connected layer

안드레 카파시? 교수가 자바로 개발한 ... 사이트
http:/cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html

### case: LeNet-5
conv, pooling, fully connected 

6 28x28 feature map 
6 14x14 feature map

### case: AlexNet
![image](https://user-images.githubusercontent.com/56099627/71069931-13074300-21bd-11ea-9fad-6a8a0a07b335.png)  
2개의 GPU을 가지고 CNN을 했기에 인풋이후 부터 2개로 나눠 CNN 되고 있음
input : 227x227x3 
1st conv1 : 55x55x96 : 96 11x11 filters, 4 stride, 55= (227-11)/4+1 : parameters 34,848 = 11x11x3x96 
2nd pool1 : 27x27x96 : 3x3 filters, 2 stride, 27= (55-3)/2+1 : parameters = 0 (파라미터는 conv에만 있음)



참고  
[1] http://cs231n.stanford.edu/2016/syllabus.html, (설명) Andu song  
[2] https://www.youtube.com/watch?v=rdTCxAM1I0I, cs231n 7강 CNN  
